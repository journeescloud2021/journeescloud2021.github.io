# Rooms
- Amphi, 400

# Papers

## Automating Multi-objective Network Slice Placement with Machine Learning: a Heuristically Assisted Deep Reinforcement Learning solution

- Alves Esteves Jose
- Jurandir Boubendir Amina
- Guillemin Fabrice
- Sens Pierre

*abstract*:
Network Slicing is a major stake in 5G networks, which is mainly enabled by Network Function Virtualization (NFV) and Software Defined Networks (SDN). These two paradigms enable telcos to offer virtual networks meeting specific needs of the vertical markets. An important challenge in the implementation at scale of Network Slicing is Network Slice Placement and the optimal allocation of virtualized resources. This can be formulated as a multi-objective Integer Linear Programming (ILP) problem. However, ILP suffers from combinatorial explosion when solving NP-hard problem, especially for large-scale scenarios. Heuristics and machine learning (ML) algorithms are efficient means of tackling this kind of problem.  We propose an approach based on heuristics used to control the learning and execution of Deep Reinforcement Learning (DRL) algorithms, which usually act as black boxes. We mainly address the problem of increasing the reliability of DRL in realistic non-stationary network conditions. First, we present a Heuristically Assisted DRL (HA-DRL) slice placement solution. This solution relies on the Advantage Actor Critic (A3C) algorithm for fast learning, and Graph Convolutional Networks (GCN) for feature extraction automation. Then, we discuss the evaluation results obtained from extensive simulations considering a fully online learning scenario and assuming that the slice request arrivals are non-stationary. The proposed HA-DRL approach speeds up the learning process, achieves a substantial gain in resource utilization, reduces performance degradation, and is more reliable under unpredictable changes in network load than non-controlled DRL algorithms. 

## QoS-aware Network Slicing for LoRaWAN: Towards Edge-to-Network Integration in Beyond 5G and 6G
- Aimi Alessandro 
- Amina Boubendir
- Fabrice Guillemin 
- Stephane Rovedakis 
- Stefano Secci

*abstract*:
With the evolution of networks to meet new requirements and demands identified in most societal and industrial use cases, the need is higher for integrating key enabling technologies such as IoT, Edge, and network intelligence for Beyond 5G and 6G. From a Telco perspective, Network Slicing appears as a central paradigm for this integration, enabling customized network services and reuse of infrastructures for fine grained specification of services and SLAs. IoT is a prevalent part of connected devices and is expected to rapidly grow in the future.  However, while there are many solutions to Slicing in 5G cellular networks, concrete proposals are missing in the context of IoT access networks and Multi-access Edge Computing (MEC).  We address these challenges within the LoRaWAN technology. The radio resource allocation needed for Slicing is a challenging problem in IoT because the access of devices to  the network is random and often massive. This is especially true in LoRaWAN networks, as  access is based on an ALOHA-like technique that does not  allow an easy partition  of resources.   We first present a proposed QoS-based IoT slicing method of i) effectively isolating slices with different QoS requirements in order to avoid failure propagation, ii) granting resources capable of meeting  QoS requirements, and iii) optimizing resource utilization and energy consumption. Then, we discuss how to the network operator can ensure SLA compliance in function of the number of devices that can be served by each IoT network access gateway.

## The PiSeduce Project
- Jean-Marc Menaud

*abstract*:
La plateforme grid5000 fournit un service de réservation de serveurs permettant, entre autres, de reproduire des infrastructures lourdes comme celles des centres de données. Avec le projet PiSeduce, nous souhaitons construire un service de réservation de nano-ordinateurs (singleboard computers) dédié à l'étude du Edge Computing. Cette plateforme, basée sur le populaire Raspberry Pi, propose une infrastructure géo-distribuée de clusters de Raspberry Pi 3 et 4. Contrairement à une infrastructure composée de serveurs, l'infrastructure proposée ici est rapide à mettre en place, facile à administrer et relativement bon marché.

## Automated performance prediction of microservice applications using simulation
- Clément COURAGEUX-SUDAN
- Anne-Cécile ORGERIE
- Martin QUINSON
  
*abstract*:
Microservices transform monolithic applications into simple, scalable, and interacting services. It allows for faster development and fine-grained deployments. However, the cooperation of several services leads to intricate dependencies, hindering the detection of performance bottlenecks. Current microservice performance analysis methods require real deployments, a costly process both in time and resources, while performance prediction through simulation relies on models that are complex to develop and instantiate. In this paper, we propose a microservice performance analysis approach based on simulation. Our contribution first introduces a microservice performance model requiring few instantiation parameters. We then propose a methodology to automatically derive model instantiation values from a single execution trace. We evaluate this methodology on two benchmarks from the literature. Our approach accurately predicts the deployment performance of large-scale microservice applications in various configurations from a single execution trace. This provides valuable insights on the performance of an application prior to its deployment on real platform.  Cet article à été soumis et accepté à la conférence MASCOTS 2021

## Externalisation Sécurisée vers un environnement cloud computing basée sur la génétique humaine
- HAMMAMI, Hamza

*abstract*:
Le cloud computing désigne une infrastructure informatique dans laquelle les données et les logiciels sont conservés et traités à distance dans le data center du fournisseur du cloud, accessibles en tant que service par le biais d'Internet. Les entreprises aspirent à prendre de plus en plus connaissance de cette avancée car elle va sûrement bouleverser le marché d'aujourd'hui compte tenu de plusieurs facteurs, notamment ses architectures rentables, prenant en charge la transmission, le stockage et le calcul intensif des données. Le cloud computing apparaît donc comme une opportunité formidable pour les entreprises, mais comme toute nouvelle technologie, elle pose de nouveaux problèmes de sécurité qui constituent un obstacle au recours vers cette technologie. Pour cela, des utilisateurs hésitent à recourir au cloud, mettant en cause la sécurité et la protection des données privées, l'incapacité de contrôler les informations dès qu'elles quittent le périmètre et le manque de confiance envers les prestataires des services cloud. Les appréhensions autour des questions de sécurité restent le principal frein à l'adoption du cloud par les entreprises. Elles ont, par voie de conséquence, poussé de nombreux chercheurs à s'intéresser à ce sujet délicat dans le but essentiel de promouvoir la sécurité des données des utilisateurs lors de leurs migrations vers le cloud et la protection des services fournis par le cloud lors de leurs déploiements en suggérant des approches et des techniques de protection. La réflexion menée dans ce travail s'inscrit dans le cadre de cette problématique. Elle concerne, d'une part, l'étude des mécanismes de sécurité proposés visant à assurer la sécurité des données dont les deux champs d'investigation sont : la gestion des accès aux données des utilisateurs distants et la gestion de la confidentialité de ces données dans le cloud et, d'autre part l'exploration des possibilités d'adoption des opportunités offertes par ces mécanismes en particulier ceux intéressant la génétique humaine, afin de pouvoir élaborer et dresser nos contributions dans ce domaine. Dans cette optique, nous  comptons pousser encore davantage cet aspect de la génétique humaine et nous essayons ainsi d'exploiter les opportunités offertes par cette technique prometteuse concernant la sécurité.  En effet, et à ce propos, nous avons envisagé dans notre première contribution l'utilisation de la génétique humaine, en particulier la biosynthèse des protéines pour bénéficier de ses découvertes avantageuses afin d'assurer une migration complètement sécurisée de toutes les données des utilisateurs distants lors de leurs migrations vers le cloud tout en assurant la confidentialité et l'intégrité de ces données, et ce grâce à la cryptographie ADN. Dans la deuxième et la troisième contributions, nous avons fait un schéma de sécurité permettant à un utilisateur distant d'accéder à ses données grâce à une authentification basée sur la signature de son rythme cardiaque et d'assurer une migration complètement sécurisée de toutes ses données n'importe où dans le cloud. Dans la quatrième contribution, nous avons établi un système de détection d'intrusions basé sur le système immunitaire artificiel. Ce système constitue un moyen de sécurité intéressant pour le paradigme du cloud computing dans le but d'étudier les objectifs des attaquants et de permettre ainsi aux administrateurs du cloud d'être toujours au courant des techniques d'attaque récentes. 

## StorNIR: une stratégie multi-objectifs de placement de répliques  pour un Cloud fédéré
- Chikhaoui Amina 
- Lemarchand Laurent
- Boukhalfa Kamel
- Boukhobza Jalil

*abstract*:
La fédération de Clouds permet d'étendre de manière transparente les ressources des fournisseurs de services Cloud (CSP: Cloud Service Providers). Pour les services de stockage, plusieurs métriques doivent être optimisées afin de satisfaire la QoS des clients, par exemple les performances d’E/S de stockage, la latence du réseau, ou encore, la disponibilité des données. La réplication des données est une stratégie clé pour optimiser ces métriques. Pour un CSP membre d'une fédération, un placement efficace des répliques d'objets des clients est crucial pour satisfaire les exigences de QoS. Dans ce travail, nous avons modélisé le problème de placement de répliques dans une fédération sous forme d’un problème d’optimisation multi-objectifs en tenant compte des différentes caractéristiques du système de stockage local, des services de stockage externes et des SLA (Service Level Agreement) des clients ainsi que leur charge de travail. Pour résoudre ce problème, nous avons proposé StorNIR, une stratégie de stockage d'objets basée sur NSGAII et mise à niveau avec des opérateurs d'injection et de réparation. StorNIR est une matheuristique qui consiste à hybrider une méthode exacte avec la méta-heuristique NSGAII. Un opérateur de réparation a été conçu pour rendre les solutions réalisables au regard des contraintes du système (volume de stockage, IOPS etc.). L'évaluation a montré que  StorNIR fournit de meilleurs résultats que la méta-heuristique NSGAII et la méthode exacte en termes de qualité des solutions et de passage à l’échelle. La fonction de réparation améliore la méta-heuristique NSGAII jusqu'à 7 fois avec 7,4% de temps d'exécution supplémentaire. En moyenne, StorNIR améliore de 17 fois la qualité des solutions initiales calculées par CPLEX en termes d'Hypervolume. De plus, l'approche matheuristique conçue peut être généralisée à d'autres méta-heuristiques que NSGAII telles que la méta-heuristique MOPSO. StorNIR permet aussi d’établir un compromis entre la qualité des solutions et le temps d'exécution en ajustant la fonction d'injection. 

## Accelerating AI at the Edge and offloading it to the Cloud
- Ouarnoughi Hamza

*abstract*:
Processing and storage requirements for next generation Autonomous Driving (AD) will be important and will exceed the in-board capacity of the vehicle. A multi-level framework for AD tasks will be able to augment the computation and storage power by offloading complex applications from the constrained embedded platforms to fog and cloud computing nodes. Processing and memory capacities of these higher levels of the hierarchy may provide an effective way to implement complex AD functionalities. Our goal is to come up with a task-mapping framework where decisions will be made at different levels of the framework depending on time sensitivity, available resources, energy constraints, and accuracy requirements. We propose a 3-level architecture along with a runtime policy to efficiently manage heterogeneous Hardware (HW)/Software (SW) resources for AD applications used in Intelligent Transport System (ITS). The 3 levels are: Edge level which corresponds to HW/SW resources within the vehicle, Fog level which corresponds to HW/SW resources available in the road infrastructure and finallyCloud level which provides high performance computing and storage servers and capabilities. The presentation will give an overview of the current and the future work on the proposed framework.

## IoT Data Replication and Consistency Management in Fog Computing NAAS

- Mohammed Islam
- LEMARCHAND Laurent
- RAIPIN Philippe
- BOUKHOBZA Jalil
  
*abstract*:
Le Fog Computing est apparu comme une plateforme virtuelle étendant les services du Cloud jusqu'à la périphérie du réseau, en particulier pour héberger des applications d’IoT. Des stratégies de réplication de données ont été conçues pour étudier le meilleur emplacement de stockage des copies de données (réplicas) dans des systèmes de stockage géo-distribués, afin de réduire leur temps d'accès pour différents services consommateurs répartis sur l'infrastructure. Cependant, en raison de la distance géographique existante entre les nœuds Fog, le mauvais placement de données dans une telle infrastructure peut générer des latences élevées lors de l'accès ou de la synchronisation des réplicas, dégradant ainsi la qualité de service (QoS). Dans ce travail, nous présentons deux stratégies de gestion de la réplication et de la cohérence des données d’IoT dans les infrastructures Fog. Nos stratégies choisissent pour chaque donnée, le bon nombre de réplicas ainsi que leur emplacement afin de réduire (i) la latence d'accès aux données et (ii) le coût de synchronisation des réplicas. Cela se fait en respectant le niveau de cohérence requis pour chaque donnée. Aussi, nous proposons une plateforme d'évaluation basée sur le simulateur iFogSim pour permettre aux utilisateurs de mettre en œuvre et de tester leurs propres stratégies de gestion de la réplication et de la cohérence de données d’IoT dans les infrastructures Fog. Nos expériences montrent qu'en utilisant nos stratégies, la latence de service peut être réduite de 30% dans le cas de petites infrastructures Fog (comprenant plusieurs dizaines de nœuds) et de 13% dans le cas d'infrastructures Fog à grande échelle par rapport à iFogStor, une stratégie existante du placement de données d’IoT qui n'utilise pas la réplication.

## Working with logs to detect anomalies in cloud platforms
- Arthur Vervaet
- Raja Chiky 
- Mar Callau-Zori

*abstract*:
Within today’s large-scale systems, one anomaly can impact millions of users. Detecting such events in real time is essential to maintain the quality of services. It allows the monitoring team to prevent or diminish the impact of a failure. Logs are a core part of software development and maintenance by recording detailed information at runtime. Such log data are universally available in nearly all computer systems. They enable developers as well as system maintainers to monitor and dissect anomalous events. For Cloud computing companies, automatizing the anomaly detection process is a promising way to ensure the scalability of monitoring capacities regarding the increasing volume of logs generated by modern systems. Our work is part of a research chair between the French Cloud provider 3DS OUTSCALE and the LISITE-ISEP research lab. In this talk, we will cover our work toward the creation of a distributed system to detect anomalies in real time within a Cloud Computing environment where millions of log lines are produced every second. This includes parsing log streams online and in real time and working with machine learning models for anomaly detection. Presented work was accepted at the 2021 edition of the International Conference on Data Engineering (IEEE ICDE) under Ph.D. Symposium track.  About the authors: Arthur Vervaet is a Ph.D. student at the Cloud Computing company 3DS OUTSCALE and at the research lab LISITE-ISEP. His research area covers stream processing and machine learning for anomaly detection. His thesis is supervised by Raja Chiky, Professor at the LISITE-ISEP laboratory Mar Callau-zori, Doctor of Mathematics from the Universidad Politécnica de Madrid and head of the data lake team at 3DS OUTSCALE. 

## Horizontal scaling in cloud using contextual bandits
- Delande David
- Stolf Patricia
- Feraud Raphael
- Pierson Jean-Marc
- Bottaro André

*abstract*:  
One characteristic of the Cloud is elasticity: it provides the ability to adapt resources allocated to applications as needed at run-time. This capacity relies on scaling and scheduling. In this article online horizontal scaling is studied. The aim is to determine dynamically applications deployment parameters and to adjust them in order to respect a Quality of Service level without any human parameters tuning. This work focuses on CaaS (container-based) environments and proposes a partially reactive Reinforcement learning algorithm based on contextual bandits (HSLinUCB). Our proposal has been evaluated on a simulated platform and on a real Kubernetes’s platform. The comparison has been done with several baselines: threshold based auto-scaler, Q-Learning, and Deep Q-Learning. The results show that HSLinUCB gives very good results compared to other baselines, even when used without any training period.

## Out of Hypervisor: Case of Intel PML
- Stella Bitchebe

*abstract*:
Ces dernières années ont vu l'intégration, par les fabricants de processeurs, de plusieurs fonctionnalités matérielles pour la virtualisation du CPU (e.g., Intel VT-x, AMD-V), de la mémoire (par exemple, Intel EPT, AMD NPT), des périphériques d'entrée/sortie (e.g., Intel VT-d, AMD-Vi), et de nombreux autres composants de la carte mère (e.g., Intel APICv, AMD AVIC), afin de simplifier la mise en œuvre des hyperviseurs et d'améliorer leur efficacité. Comme la virtualisation a été acceptée dans la plupart des datacenters, des fonctionnalités de virtualisation ont été massivement utilisées jusqu'à présent par les fournisseurs et les développeurs d'hyperviseurs. Toutefois, à notre connaissance, aucun travail de recherche n'a étendu le concept de virtualisation assistée par le matériel à d'autres contextes, qu'il s'agisse de l'hyperviseur ou de la virtualisation en général. Néanmoins, nous pouvons relever quelques idées qui présentent une notion d'hyperviseur très simplifié. C'est le cas de Dune qui est la première contribution dans ce sens et la plus connue. Dune fournit aux applications un accès direct aux fonctionnalités matérielles, mais ce, via un module qui agit comme un hyperviseur (même si très simplifié comparé à un hyperviseur ordinaire). Nous présentons un nouveau concept suivant le principe "OoH: Out-of-Hypervisor". L'idée ici est que nous pouvons tirer davantage profit des fonctionnalités de virtualisation car elles offrent des facilités qui peuvent également être utiles pour les applications à l’intérieur des machines virtuelles. Pour démontrer la pertinence de OoH, nous identifions deux premières idées qui exploitent des fonctionnalités récentes des processeurs Intel: Page Modification Logging (PML) et EPT-Based Sub-Page write Protection support (SPP), introduites respectivement en 2015 et 2018. Ces fonctionnalités ne sont actuellement accessibles que par l'hyperviseur bien qu'elles fournissent des facilités qui sont également indispensables à l'intérieur des machine virtuelles (VMs). En effet, le PML est une fonctionnalité qui permet à l'hyperviseur de traquer les adresses physiques (dans l'espace d'adressage de la VM) de toutes les pages mémoire modifiées par une VM. Cela pourrait être utile pour les opérations de checkpoint/restore des applications et conteneurs dans la VM. Et quant à SPP, elle permet à l'hyperviseur de spécifier des droits d'accès en écriture pour protéger la mémoire physique de la VM, ceci à la granularité d'une sous-page (128 octets), ce qui pourrait être avantageux pour lutter contre les attaques mémoire telles que les buffer overflow, même dans l'espace utilisateur de la VM. Dans cet abstract nous nous intéressons à l’utilisation d'Intel PML pour le Checkpoint/Restore (C/R) des applications et containers dans l'espaceutilisateur de la VM. Le C/R est une opération qui permet d'assurer la tolérance aux pannes des systèmes informatiques. Elle consiste à sauvegarder une image de l'état d'une application afin de pouvoir la restaurer en cas de panne. Les solutions récentes de C/R et les plus efficaces consistent en général à invalider le bit dirty (le mettre à 0) des pages mémoires des applications à monitorer. Ainsi, lors des prochains accès le bit dirty des pages modifiées (qui sont celles à traquer pour l'opération de C/R) sera remis à 1. Ces solutions peuvent générer des dégradation de performance importantes pour les applications concernées, liées aux défauts de pages qu'entraine l'invalidation du bit dirty. Il serait donc très intéressant de pouvoir récupérer les adresses des pages modifiées sans avoir besoin au préalable d'invalider leur bit dirty. Ceci est exactement le but du PML qui permet à l'hyperviseur de pouvoir connaître toutes les adresses physiques (dans l'espace d'adressage de la VM) des pages modifiées par une VM durant son exécution. Seulement, le PML n'est utilisable actuellement que par l'hyperviseur. Notre objectif avec OoH est donc d'étendre l'utilisation du PML à la machine virtuelle pourqu'ainsi, au lieu d'invalider les bit dirty des applications, l'utilisateur puisse obtenir les informations sur les pages modifiées directement du processeur qui enregistre les adresses correspondantes dans un espace mémoire (accessible à l'utilisateur).

## Quand les données IoT rencontrent le streaming multimédia dans le Fog
- Lydia AIT OUCHEGGOU 
- Mohammed Islam NAAS
- Yassine HADJADJ-AOUL
- Jalil BOUKHOBZA

*abstract*:
L'Internet des objets (IoT) et les services de streaming multimédia représentent aujourd'hui les principales sources de données numériques. La méthode traditionnelle de stockage des données dans le Cloud est incapable de satisfaire des contraintes de latences d’un grand nombre d'applications. C'est pour cette raison que le paradigme Fog a été introduit. Le placement de données de nature hétérogène, comme les données d’IoT et de streaming, dans une telle infrastructure est critique pour les fournisseurs d'accès à Internet (ISP). En effet, en cas de violation des accords de niveau de service (SLA), une pénalité est appliquée. Or cette problématique a été traitée de manière séparée dans l’état de l’art : (i) le problème du placement des données IoT et (ii) le problème du placement des données de streaming dans les caches. Dans ce travail, nous abordons les deux problèmes dans un modèle unique, car utilisant les mêmes systèmes de stockage, dans le but de minimiser la pénalité pour les ISPs encourue par la violation des SLA. Notre modèle vise à, partitionner le système de stockage en deux parties, une pour les données de l’IoT et l’autre pour les données de streaming. Notre solution de placement, consiste, en premier lieu, à placer les données IoT dans la partition dédiée des nœuds de fog, puis à placer les données de streaming dans la partie dédiée de ces mêmes nœuds. La nouveauté de notre modèle est la flexibilité du volume utilisé comme cache pour les données de streaming, qui peuvent, à la demande, déborder sur la zone libre de la partition de stockage des données IoT.  Nous avons formulé le problème de placement des données IoT sous forme d’un problème d'affectation généralisée (GAP), et le placement des données de streaming dans le cache comme un problème de P-médian. Les expériences menées ont montré que la pénalité générée par notre solution est réduite de plus de 47 fois en comparaison à la combinaison des méthodes traditionnelles qui existent dans la littérature.

## Geo-Distribute Cloud Applications at the Edge
- Delavergne Marie 
- Antony Geo Johns 
- Lebre Adrien

*abstract*:
With the arrival of the edge computing a new challenge arises for cloud applications: How to benefit from geo-distribution (locality) while dealing with inherent constraints of wide-area network links?  The admitted approach consists in modifying cloud applications by entangling geo-distribution aspects in the business logic using distributed data stores. However, this makes the code intricate and contradicts the software engineering principle of externalizing concerns.  We propose a different approach that relies on the modularity property of microservices applications: (i) one instance of an application is deployed at each edge location, making the system more robust to network partitions (local requests can still be satisfied), and (ii) collaboration between instances can be programmed outside of the application in a generic manner thanks to a service mesh.  We validate the relevance of our proposal with Cheops, a PoC that aims to be generic regarding the application, and which we tested upon Kubernetes and OpenStack. In particular, we present three types of collaboration: sharing, replication and cross.

## Pythia: Mobility Intelligence Understanding Towards Resource-efficient MEC Systems
- Pedro Cruz
- Nadjib Achir
- Aline Carneiro
- Viana Luís Henrique
- Maciel Kosmalski Costa

*abstract*:
The most relevant aspect of Multi-Access Edge Computing (MEC) is to provide computing resources close to the User Equipment (UE). MEC hosts serve UEs according to some allocation strategy. An allocation strategy defines which MEC host should serve each of the applications running in the UEs. Among other variables, the optimal allocation strategy should consider the distance between UEs and MEC hosts, the available resources, and the needs of each UE application. In a scenario with high user mobility, the distance between a given UE and each MEC host is dynamic, creating a risk to MEC's primary aspect, which is to be close to the UE. To mitigate this problem, it is important to develop mobility-aware allocation strategies, capable of anticipating user demands. Nevertheless, per-user short-term mobility understanding still remains limited and requires particular attention. For this reason, allocation strategies to mitigate limitations inherent to mobility may result in imprecise demand anticipations and consequently, in allocation errors. These two issues are amplified by the lack of tools available to emulate MEC systems and evaluate the mobility impact and possible mitigation strategies. In this work, we propose Pythia, a MEC system emulator that receives (i) users' mobility information (UE mobility traces), (ii) MEC infrastructure specifications, (iii) a pair containing a MEC and a UE application, and (iv) an allocation strategy, outputting important metrics of user experience. In such a way, Pythia extracts and models properties of short-term mobility behavior of users to anticipate future locations in users' mobility. Such information is then leveraged at the MEC allocation of resources. Pythia emulates the network from the point-of-view of the links between the MEC hosts and the UEs while executing the MEC and UE applications in a virtual environment. We intend to present Pythia as a work in progress, its architecture, tools, and preliminary results.


## Intel SPP et les buffer overflows
- Yves Kone 
- Mukam Augusta

*abstract*:
Un dépassement / débordement de tampon ou buffer overflow survient lorsqu’un processus écrit à l'extérieur de l'espace alloué à ce tampon, écrasant éventuellement les informations contenues dans des tampons adjacents. Ce phénomène peut être provoqué par des erreurs de programmation en indiquant une borne trop grande lors du parcours d’un tableau par exemple. Ce bug est bien connu car il a facilité la prolifération de nombreuses attaques au fil des années. D'après le classement des vulnérabilités les plus dangereuses de 2021 du Common Weakness Enumeration (CWE), les buffer overflows occupent la première place.   Dans l'état de l'art,  il   existe   plusieurs   techniques   permettant   de prévenir les buffer overflows à différents niveaux. Nous pouvons citer les canaris qui permettent uniquement de détecter de manière asynchrone les overflows avec un très léger surcoût mémoire, et les guardpages dont la détection est synchrone mais avec un surcoût mémoire plus conséquent. Cependant, ces méthodes présentent naturellement des inconvénients réduisant ainsi leur efficacité.  Intel a mis au point une technologie matérielle (Subpage Write Protection) visant à réduire la granularité de la mémoire pour les accès en écriture dans un environnement virtualisé. Ils introduisent la notion de subpage: morceau de mémoire contigu de 128 octets auquel on peut autoriser ou non les écritures. Cette technologie étant initialement prévue pour le monitoring ou encore le checkpointing, elle peut-être détournée pour sécuriser la mémoire. En effet, en plaçant un buffer à la frontière d'une subpage protégée, il est possible de détecter et d'empêcher les overflows de ce buffer à l'image des guardpages mais à moindre coût. A priori, cette solution est un bon compromis entre les canaris et les guardpages. Notre objectif est de pouvoir manipuler les accès en écriture des subpages d'une machine virtuelle depuis l'espace utilisateur.  Néanmoins, la protection de buffer par des mécanismes de détection seule n'est pas encore optimale. En effet, pour que l'application soit complètement protégée des buffer overflows, il faudrait que chacun des buffers soit suivi d'une subpage protégée : la consommation mémoire de l'application serait alors énorme. Pour pallier cela, il serait alors plus judicieux d'identifier et de ne protéger seulement les tampons les plus susceptibles de provoquer des overflows.  C'est ainsi que nous décidons d'analyser le code de l'utilisateur, notamment l'ensemble des opérations effectuées sur la mémoire, pour identifier les opérations sensibles et ainsi pénaliser les zones mémoire à risque.  Nous optons donc pour une analyse du code intermédiaire généré à la compilation du programme utilisateur, cela grâce à l'infrastructure de compilation LLVM, afin de ressortir l'ensemble des allocations mémoire à protéger.  Pour cela, nous étudions les instructions dites sensibles impliquant un déréférencement de pointeur.  Ces instructions seront pénalisées en suivant le principe de l'article de Dowser.  Ces allocations mémoire sensibles seront donc protégées suivant leur pénalité obtenue grâce au mécanisme de SPP décrit au départ.  Nous proposons une solution reposant sur deux aspects, un mécanisme de protection de buffer efficace et une politique de classification de buffer pour amortir les surcoûts mémoire engendrés par la technologie Intel SPP.  Ainsi, globalement notre solution permet de protéger la mémoire de tout débordement tampon au moment de la phase de compilation.

## Virtual Disk Snapshot Management at Scale
- Kevin Nguetchouang

*abstract*:
All this is about data, Sometimes in enterprise, we need to do backup, in order to have a traceability of the data, this is good either for clients confidentiality and for the entreprise itself. As Computer science is fully used in almost every domain, cloud providers really struggles to offer as much as storage needed for the differents VMs of their clients. In order to resolve this problem, some virtual disk formats emerged and they are focused on using less storage size to do differents backup of the same VMs; such as VMDK (of VMware), VHD(of Microsoft) and Qcow2(of Qemu/KVM) The principle is simple. when a backup is done, we don't create a new file for the VM, but we create an empty image file for new writes operations so that VM could continue to access data presented in previous backup without modifying them and without duplicating them. This works well when we do a few number of backups (10-100), But what happened when an entreprise do more than 500 ? and when the cloud provider himself have to create backup over backup of clients VMs in order to ensure fault tolerance ? Well, with this technique used by all those virtual disk, applications performance running in VMs are seriously impacted, due to the fact that Each read operation need to go through all the snapshot chain in the worst case in order to find the data. We do some previous test, and we see that for a VM snapshot 1000 times (counting clients snapshotting and cloud providers unknow snapshotting), the VM starts in about 45min. So we focus our research on the most popular and most used virtual format disk (Qcow2) to propose a solution for this problem, which consists on storing a new entry in each cluster metadata - cluster here is the granularity of division of the virtual disk - which is the snapshot index where the last modification of this cluster was made so that each cluster can "remember" where it was modify the last time; so, instead of going through all the snapshot chain at each read/write operation, We can just point on the snapshot by this "snapshot_index".  While investigating and designing our solution for Qcow2, we noticed that qemu was managing each snapshot individually. There was one cache per snapshot and sometimes metadata for cluster was entirely duplicated over many of thoses snapshot. We propose also a lesser modification in the design of this cache in order to have a common cache for a whole chain of snapshots. Our first evaluation results show us a diminution of 80% of memory consumption but we still have to do more evaluation in a macro view and in a minor view with micro metrics in order to explain and justify why it works (our solution) and why it's simple to use.

## Supporting time in the graph-of-objects platform Thing'in
- Maria Massri

*abstract*:
Graphs are used in a myriad of application domains to model relationship-centered data. In this context, Thing'in (https://www.thinginthefuture.com/) is a platform that uses a graph to model the connections between connected (smoke detector, cameras, printers, etc.) and non-connected (rooms, tables, roads, etc.) objects. However, smart devices embed a highly dynamic behavior leaving the graph of Thing'in to be naturally modeled as a temporal graph. Indeed, analyzing such a dynamic behavior opens the way to promising applications that enlarge the spectrum of what Thing'in is offering today. In order to keep pace with this demand, a graph management system with an optimized time-version support is needed.  Having this, our main motivation is the design and integration of a temporal graph management system into the Thing’in platform. Towards accomplishing this goal, we mainly tackled two challenges that are: the storage techniques and querying languages. Hence, we proposed a space-efficient storage technique that is motivated by the concept of logging and checkpointing found in classic techniques of database state recovery. Besides, we extended the well known graph query language Cypher with user-friendly temporal constructs that permits a straight-forward transition for practitioners who are already familiar with the language to naturally add the temporal dimension when reasoning about queries.


## Impacts of Service Decomposition Models on Security Attributes: A Case Study with 5G Network Repository Function	
- BEHRAD Shanay 
- ESPES David 
- BERTIN Philippe
- PHAN Cao-Thanh

*abstract*:
Microservices-based architectures gain more and more attention in industry and academia due to their tremendous advantages such as providing resiliency, scalability, composability, etc. To benefit from these advantages, a proper architectural design is very important. The decomposition model of services into microservices and the granularity of these microservices affect the different aspects of the system such as flexibility, maintainability, performance, and security. An inappropriate service decomposition into microservices (improper granularity) may increase the attack surface of the system and lower its security level. In this paper, first, we study the probability of compromising services before and after decomposition. Then we formulate the impacts of possible service decomposition models on confidentiality, integrity, and availability attributes of the system. To do so, we provide equations for measuring confidentiality, integrity, and availability risks of the decomposed services in the system. It is also shown that the number of entry points to the decomposed services and the size of the microservices affect the security attributes of the system. As a use case, we propose three different service decomposition models for the 5G NRF (Network Repository Function) and calculate the impacts of these decomposition models on the confidentiality, integrity, and availability of the system using the provided equations.


## Micro-Services IDE: Challenges for a modular and distributed language services implementation
- Olivier Barais
- Benoit Combemale

*abstract*:
Integrated Development Environments (IDEs) are indispensable companions to programming languages. They are increasingly turning towards Web-based infrastructure. The rise of a protocol such as the Language Server Protocol (LSP) that standardizes the separation between a language-agnostic IDE, and a language server that provides all language services (\emph{e.g.,} auto completion, compiler…) has allowed the emergence of high quality generic Web components to build the IDE part that runs in the browser. However, all language services require different computing capacities and response times to guarantee a user-friendly experience within the IDE. The monolithic distribution of all language services prevents to leverage on the available execution platforms (e.g., local platform, application server, cloud). In contrast with the current approaches that provide IDEs in the form of a monolithic client-server architecture, we explore in this paper the modularization of all language services to support their individual deployment and dynamic adaptation within an IDE. We evaluate the performance impact of the distribution of the language services across the available execution platforms on four EMF-based languages, and demonstrate the benefit of a custom distribution.


# Events

## (CoffeeBreak) Coffee break

## (CoffeeBreak) Lunch

## (CoffeeBreak) Opening
## (Opening) Welcome session

## (Keynote) Infrastructure Cloud privé embarquée pour le domaine naval militaire
- Christophe Baixas

*abstract*:
To be announced
**[Christophe Baixas](https://www.linkedin.com/in/christophe-baixas-4620b41/?)**

## (Keynote) Philipe Merle's Keynote
- Philipe Merle

*abstract*:
⚠️TO be announced⚠️<p></p>
**Bio**: Philippe Merle is senior researcher at Inria since 2002 and is member of the Spirals research team. He was associate professor at
University of Lille 1, France. He obtained a PhD degree in computer science from University of Lille 1. His research is about software engineering for distributed systems, especially cloud computing, service oriented computing, middleware, model driven engineering,
and component-based software engineering.<p></p>
**[Site Web personnel](http://chercheurs.lille.inria.fr/~pmerle/)**

## (Keynote) Ivan Meriau's Keynote
- Ivan Meriau
- David Tardivel
- Pierre Crégut

*abstract*:
⚠️TO be announced⚠️
Ivan Meriau, David Tardivel, Pierre Crégut
[IRT b<>com](https://b-com.com)

## (Keynote) mck8s: An Kubernetes-based orchestration platform for geo-distributed multi-cluster environments

- Guillaume Pierre

*abstract*:
Following the adoption of cloud computing, the proliferation of cloud data centers in multiple regions, and the emergence of computing paradigms such as fog computing, there is a need for integrated and efficient management of geodistributed clusters. Geo-distributed deployments suffer from resource fragmentation, as the resources in certain locations are over-allocated while others are under-utilized. Orchestration platforms such as Kubernetes and Kubernetes Federation offer the conceptual models and building blocks that can be used to build integrated solutions that address the resource fragmentation challenge. In this work, we propose mck8s-an orchestration platform for multi-cluster applications on multiple geo-distributed Kubernetes clusters. It offers controllers that automatically place, scale, and burst multi-cluster applications across multiple geo-distributed Kubernetes clusters. mck8s allocates the requested resources to all incoming applications while making efficient use of resources.
We designed mck8s to be easy to use by development and operation teams by adopting Kubernetes' design principles and manifest files. We evaluated mck8s in a geo-distributed experimental testbed in Grid'5000. Our results show that mck8s balances the resource allocation across multiple clusters and reduces the fraction of pending pods to 6% as opposed to 65% in the case of Kubernetes Federation for the same workload.<p></p>
**Bio**: Pr Guillaume Pierre is Professor at Univ Rennes 1. He is leading the Myriads research team (INRIA, CNRS, Univ Rennes 1, ENS Rennes, INSA) His research interests span cloud computing, fog computing and large-scale distributed systems. He is the coordinator of the H2020 FogGuru project. He teaches courses mostly related to operating systems, distributed systems and cloud computing.<p></p>
**[Site Web personnel](http://www.globule.org/~gpierre/)**

## (Keynote) Zero touch management and orchestration of network slices in 5G and beyond networks

- Adlen. Ksentini

*abstract*:
6G systems are expected to serve a massive number of extremely heterogeneous Network Slices that cross multiple technological domains (i.e., RAN, Edge, Cloud, and Core), posing significant challenges to classical centralized management and orchestration approaches in terms of scalability and sustainability. Within this context, distributed and intelligent management and orchestration system is mandatory. This talk presents the challenges related to the management and orchestration of network slices in 5G and beyond mobile networks. Based on these requirements, a hierarchical, distributed, and AI-driven management framework is introduced, featuring a zero-touch service management concept. Finally, two use-case scenarios relaying on the proposed architecture are proposed.<p></p>
**Bio** Adlen Ksentini is a COMSOC distinguished lecturer. He obtained his Ph.D. degree in computer science from the University of Cergy-Pontoise in 2005, with a dissertation on QoS provisioning in IEEE 802.11-based networks. From 2006 to 2016, he worked at the University of Rennes 1 as an assistant professor. During this period, he was a member of the Dionysos Team with INRIA, Rennes. Since March 2016, he has been working as an assistant professor in the Communication Systems Department of EURECOM. He has been involved in several national and European projects on QoS and QoE support in future wireless, network virtualization, cloud networking, mobile networks, and more recently on Network Slicing and 5G in the context of H2020 projects 5G!Pagoda, 5GTransformer, 5G!Drones and MonB5G. He has co-authored over 120 technical journal and international conference papers. He received the best paper award from IEEE IWCMC 2016, IEEE ICC 2012, and ACM MSWiM 2005. He has been awarded the 2017 IEEE Comsoc Fred W. Ellersick (best IEEE communications Magazine’s paper). Adlen Ksentini has given several tutorials in IEEE international conferences, IEEE Globecom 2015, IEEEE CCNC 2017, IEEE ICC 2017, IEEE/IFIP IM 2017. Adlen Ksentini has been acting as TPC Symposium Chair for IEEE ICC 2016/2017, IEEE GLOBECOM 2017, IEEE Cloudnet 2017 and IEEE 5G Forum 2018. He has been acting as Guest Editor for IEEE Journal of Selected Area on Communication (JSAC) Series on Network Softwerization, IEEE Wireless Communications, IEEE Communications Magazine, and two issues of ComSoc MMTC Letters. He has been on the Technical Program Committees of major IEEE ComSoc, ICC/GLOBECOM, ICME, WCNC, and PIMRC conferences. He acted as the Director of IEEE ComSoc EMEA region and member of the IEEE Comsoc Board of Governor (2019–2020). He is the chair of the IEEE ComSoc Technical Committee on Software (TCS). <p></p>
**[Site Web personnel](https://www.eurecom.fr/~ksentini/)**

## (Keynote) Nancy Perrot's Keynote
- Nancy Perrot

*abstract*:
⚠️TO be announced⚠️<p></p>
*[Orange](http://www.orange.fr)*

## [TalkSession] Ressource Management
### Papers
    - Horizontal scaling in cloud using contextual bandits
    - Out of Hypervisor: Case of Intel PML

## [TalkSession] Microservices and performances
### Papers

- Automated performance prediction of microservice applications using simulation
- Working with logs to detect anomalies in cloud platforms
- Micro-Services IDE: Challenges for a modular and distributed language services implementation

## [TalkSession] Cloud and storage

### Papers

- StorNIR: une stratégie multi-objectifs de placement de répliques  pour un Cloud fédéré
- IoT Data Replication and Consistency Management in Fog Computing
- Quand les données IoT rencontrent le streaming multimédia dans le Fog
- Virtual Disk Snapshot Management at Scale
- Supporting time in the graph-of-objects platform Thing'in

## [TalkSession] Cloud and security
### Papers

- Externalisation Sécurisée vers un environnement cloud computing basée sur la génétique humaine
- Intel SPP et les buffer overflows
- Impacts of Service Decomposition Models on Security Attributes: A Case Study with 5G Network Repository Function

## [TalkSession] Edge/Cloud continuum
### Papers

- The PiSeduce Project
- Accelerating AI at the Edge and offloading it to the Cloud
- Geo-Distribute Cloud Applications at the Edge

## [TalkSession] Cloud and Network
### Papers

- Automating Multi-objective Network Slice Placement with Machine Learning: a Heuristically Assisted Deep Reinforcement Learning solution
- QoS-aware Network Slicing for LoRaWAN: Towards Edge-to-Network Integration in Beyond 5G and 6G
- Pythia: Mobility Intelligence Understanding Towards Resource-efficient MEC Systems




# Program

## 2021-11-25
- 08:30 - 09:00 in Amphi : Opening
- 09:00 - 09:10 in Amphi : Welcome session
- 09:10 - 10:00 in Amphi : Infrastructure Cloud privé embarquée pour le domaine naval militaire
- 10:00 - 10:40 in Amphi : Ressource Management
- 10:40 - 11:00 in Amphi : Coffee break
- 11:00 - 11:45 in Amphi : Philipe Merle's Keynote
- 12:00 - 13:30 in Amphi : Lunch
- 13:30 - 14:15 in Amphi : Ivan Meriau's Keynote
- 14:20 - 15:20 in Amphi : Microservices and performances
- 15:20 - 15:40 in Amphi : Coffee Break
- 15:40 - 17:20 in Amphi : Cloud and storage

## 2021-11-26
- 09:00 - 09:45 in Amphi : mck8s: An Kubernetes-based orchestration platform for geo-distributed multi-cluster environments
- 09:50 - 10:50 in Amphi : Cloud and security
- 10:50 - 11:10 in Amphi : Coffee break
- 11:10 - 11:55 in Amphi : Nancy Perrot's Keynote
- 12:00 - 13:30 in Amphi : Lunch
- 13:30 - 14:15 in Amphi : Zero touch management and orchestration of network slices in 5G and beyond networks
- 14:20 - 15:20 in Amphi : Edge/Cloud continuum
- 15:20 - 15:40 in Amphi : Coffee break
- 15:40 - 16:40 in Amphi : Cloud and Network
